{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import schedule\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def job():\n",
    "    tem = time.time()\n",
    "    df = pd.read_csv('./main.csv')\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    df.drop(df[df.isnull().sum(axis = 1) > 3].index, axis = 0, inplace = True)\n",
    "    df.drop(df[df['HG_ARRAY_02'].isnull()].index, axis = 0, inplace = True)\n",
    "    df.drop(df[df['HG_ARRAY_02'] < 500].index, axis = 0, inplace = True)\n",
    "    df.drop(df[df['Wind_Velocity'] > 10].index, axis = 0, inplace = True)\n",
    "    df.drop([17], axis = 0, inplace = True)\n",
    "    name = 'solarDataProject'\n",
    "    run = 1\n",
    "    while run == 1:\n",
    "        for index, row in df[df['Wind_Velocity'].isnull()].iterrows():\n",
    "            df.loc[index, 'Wind_Velocity'] = np.random.normal(df['Wind_Velocity'].mean(), df['Wind_Velocity'].std())\n",
    "        for index, row in df[df['TT_16'].isnull()].iterrows():\n",
    "            df.loc[index, 'TT_16'] = df.loc[index, 'TT_11'] + np.random.normal((df['TT_16'] - df['TT_11']).mean(), (df['TT_16'] - df['TT_11']).std())\n",
    "        for index, row in df[df['PYNM_02'].isnull()].iterrows():\n",
    "            df.loc[index, 'PYNM_02'] = np.random.normal(df['PYNM_02'].mean(), df['PYNM_02'].std())\n",
    "        traindata, testdata, trainanswers, testanswers = train_test_split(\n",
    "            df.iloc[:, 2:7], df.iloc[:, 7], test_size = 0.2)\n",
    "        n1, n2 = np.random.randint(3, 21), np.random.randint(3, 21)\n",
    "        lr = 'constant' if np.random.randint(0, 2) == 0 else 'adaptive'\n",
    "        maxiter, iternochange = np.random.randint(5000, 15000), np.random.randint(0, 2500)\n",
    "        model = MLPRegressor(hidden_layer_sizes = (n1, n2,),\n",
    "                             learning_rate = lr,\n",
    "                             max_iter = maxiter,\n",
    "                             verbose = False,\n",
    "                             early_stopping = True,\n",
    "                             validation_fraction = 0.4,\n",
    "                             n_iter_no_change = iternochange)\n",
    "        st = time.time()\n",
    "        model.fit(traindata, trainanswers)\n",
    "        et = time.time()\n",
    "        trainpredictions = model.predict(traindata)\n",
    "        trainr2 = r2_score(trainanswers, trainpredictions)\n",
    "        testpredictions = model.predict(testdata)\n",
    "        testr2 = r2_score(testanswers, testpredictions)\n",
    "        try:\n",
    "            metrics = pd.read_csv('./metrics.csv')\n",
    "            version = metrics.loc[metrics.shape[0] - 1, 'Version'].split('.')\n",
    "            if testr2 >= metrics['testr2'].max():\n",
    "                pickle.dump(model, open('./bestmodel.nnm', 'wb'))\n",
    "                version[1] = str(int(version[1]) + 1)\n",
    "                version[2] = '0'\n",
    "                run = 0\n",
    "            else:\n",
    "                version[2] = str(int(version[2]) + 1)\n",
    "            version = version[0] + '.' + version[1] + '.' + version[2]\n",
    "            metrics = metrics.append(pd.DataFrame([[name, version, n1, n2, lr, trainr2, testr2, et - st, model.n_iter_, maxiter, iternochange, df.shape[0]]],\n",
    "                                                  columns = ['Name', 'Version', 'HL1', 'HL2', 'learning', 'trainr2', 'testr2', 'time', 'iterations', 'max_iter', 'n_iter_no_change', 'datasetsize']),\n",
    "                                     sort = False)\n",
    "            pickle.dump(model, open('./models/' + name + '.' + version + '.nnm', 'wb'))\n",
    "        except:\n",
    "            version = '0.0.0'\n",
    "            pickle.dump(model, open('./bestmodel.nnm', 'wb'))\n",
    "            metrics = pd.DataFrame([[name, str(version), n1, n2, lr, trainr2, testr2, et - st, model.n_iter_, maxiter, iternochange, df.shape[0]]],\n",
    "                                                  columns = ['Name', 'Version', 'HL1', 'HL2', 'learning', 'trainr2', 'testr2', 'time', 'iterations', 'max_iter', 'n_iter_no_change', 'datasetsize'])\n",
    "            pickle.dump(model, open('./models/' + name + '.' + version + '.nnm', 'wb'))\n",
    "            run = 0\n",
    "        metrics.to_csv(r'metrics.csv', index = False)\n",
    "\n",
    "print(schedule.every(5).seconds.do(job))\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
